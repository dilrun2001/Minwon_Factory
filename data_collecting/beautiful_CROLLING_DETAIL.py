import re
import json
import requests
from bs4 import BeautifulSoup

# ğŸ”— ëª©ë¡ ì¡°íšŒ URL
list_url = "https://eminwon.saha.go.kr/emwp/gov/mogaha/ntis/web/emwp/cns/action/EmwpCnslWebAction.do"

# ğŸ“Œ ìš”ì²­ í—¤ë” ì„¤ì •
headers = {
    "User-Agent": "Mozilla/5.0",
    "Content-Type": "application/x-www-form-urlencoded",
}

# âœ… ì „ì²´ ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
tinyllama_data = []

# âœ… í˜ì´ì§€ ë°˜ë³µ
for page in range(1, 2):  # 2025ê¹Œì§€ì˜ ë°ì´í„°ë¥¼ í¬ë¡¤ë§  276
    print(f"ğŸ“„ í˜ì´ì§€ {page} ì²˜ë¦¬ ì¤‘...")

    list_data = {
        "method": "selectCnslWebPage",
        "menu_id": "EMWPCnslWebInqL",
        "jndinm": "EmwpCnslWebEJB",
        "methodnm": "selectCnslWebPage",
        "context": "NTIS",
        "pageIndex": str(page),
        "pageSize": "20"
    }

    try:
        response = requests.post(list_url, data=list_data, headers=headers)
    except Exception as e:
        print(f"âŒ ìš”ì²­ ì‹¤íŒ¨: {e}")
        break

    if response.status_code != 200:
        print(f"âŒ í˜ì´ì§€ {page} ìš”ì²­ ì‹¤íŒ¨!")
        break

    soup = BeautifulSoup(response.text, "html.parser")
    rows = soup.select("table.table tbody tr")

    if not rows:
        print("â›” ë” ì´ìƒ ë°ì´í„° ì—†ìŒ! ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        break

    for row in rows:
        cols = row.find_all("td")
        if len(cols) >= 2:
            title = cols[1].text.strip()
            link_tag = cols[1].find("a")
            if not link_tag:
                continue

            onclick = link_tag.get("href", "")
            match = re.search(r"fncViewDtl\('(\d+)'", onclick)
            if not match:
                continue

            cnsl_qna_no = match.group(1)

            detail_data = {
                "method": "selectCnslWebShow",
                "jndinm": "EmwpCnslWebEJB",
                "methodnm": "selectCnslWebShow",
                "context": "NTIS",
                "cnsl_qna_no": cnsl_qna_no,
            }

            try:
                detail_resp = requests.post(list_url, data=detail_data, headers=headers)
            except Exception as e:
                print(f"âŒ ìƒì„¸í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨: {e}")
                continue

            if detail_resp.status_code == 200:
                detail_soup = BeautifulSoup(detail_resp.text, "html.parser")
                tables = detail_soup.select("table.bbs-table-view")

                # ì œëª©/ì‘ì„±ì¼ ì¶”ì¶œ
                detail_title = ""
                detail_date = ""
                if tables:
                    rows_detail = tables[0].find_all("tr")
                    for tr in rows_detail:
                        ths = tr.find_all("th")
                        tds = tr.find_all("td")
                        for i in range(len(ths)):
                            th_text = ths[i].text.strip()
                            td_text = tds[i].text.strip() if i < len(tds) else ""
                            if th_text == "ì œëª©":
                                detail_title = td_text
                            elif th_text == "ì‘ì„±ì¼":
                                detail_date = td_text

                question_text = tables[0].find_all("tr")[-1].get_text(separator="\n", strip=True) if len(tables) > 0 else ""
                answer_text = tables[1].find_all("tr")[-1].get_text(separator="\n", strip=True) if len(tables) > 1 else ""

                if question_text.strip() and answer_text.strip():
                    data_item = {
                        "instruction": question_text.strip(),
                        "output": answer_text.strip()
                    }
                    tinyllama_data.append(data_item)

                    # âœ… ì œëª© + ì‘ì„±ì¼ í•¨ê»˜ ì¶œë ¥
                    print(f"âœ… ë¯¼ì› ìˆ˜ì§‘: {detail_title} (ì‘ì„±ì¼: {detail_date})")

# âœ… JSONL íŒŒì¼ë¡œ ì €ì¥
with open("data.jsonl", "w", encoding="utf-8") as f:
    for item in tinyllama_data:
        json_line = json.dumps(item, ensure_ascii=False)
        f.write(json_line + "\n")

print(f"ğŸ‰ ì´ {len(tinyllama_data)}ê°œì˜ ë°ì´í„°ê°€ tinyllama_data.jsonlì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")